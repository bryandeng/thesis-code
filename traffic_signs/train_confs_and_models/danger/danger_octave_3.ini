verbose=1
backgroundClassLabel=0

[train]

trainSetName=GTSD_danger_multiscales_octave_3

trainSet=/home/deng/datasets/GTSDB/Train_multiscales/Danger/positives_octave_3.0
testSet=

# x, y, width, height
objectWindow=32,32,384,384
modelWindow=448,448

# from training example top-left corner to model window
offsetX=80
offsetY=80

outputModelFileName=Danger_trained_model_octave_3.proto.bin

minFeatWidth=24
minFeatHeight=24

# 2000 weak classifiers
numIterations=2000

bootStrapLearnerFile=

# candidate features
featuresPoolSize=80000

# FIXME is this even used ?
#maxFeatureSizeRatio=0.9

# FIXME is this even used ?
typeAdaboost=discrete

# level 2 decision trees
decisionTreeDepth=1

# DBP means: Direct Backward Prunning (see C. Zang and P. Viola 2007)
cascadeType=dbp

numNegativeSamples = 2000

[bootstrapTrain]

# 2000 weak classifiers
classifiersPerStage=50
classifiersPerStage=100
classifiersPerStage=200
classifiersPerStage=800

#classifiersPerStage=100
#classifiersPerStage=100
#classifiersPerStage=100

#maxNumSamplesPerImage=0
#maxNumSamplesPerImage=-1
#maxNumSamplesPerImage=-1

maxNumSamplesPerImage=0
maxNumSamplesPerImage=10
maxNumSamplesPerImage=5
maxNumSamplesPerImage=-1


# number of samples collected at each stage
# first stage takes random negative samples, then we take hard negative samples
numBootstrappingSamples=2000

# defaults for GTSDB detections
min_scale = 0.33
max_scale = 2.5
num_scales = 45

#min_ratio = 0.8
#max_ratio = 1.0
#num_ratios = 5

#frugalMemoryUsage = true

[test]
classifierName=model_for_test.proto.bin
#testSet=trainfull.txt
testSet=testfull.txt


# from testing example top-left corner to model window
offsetX=80
offsetY=80
